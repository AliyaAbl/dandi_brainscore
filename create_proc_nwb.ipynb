{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from dateutil.tz import tzlocal\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import os, yaml, glob, json\n",
    "import pandas as pd\n",
    "from nwbwidgets import nwb2widget\n",
    "import pynwb\n",
    "from pynwb import NWBHDF5IO, NWBFile, TimeSeries\n",
    "from pynwb.behavior import Position, SpatialSeries\n",
    "from pynwb.epoch import TimeIntervals\n",
    "from pynwb.file import Subject\n",
    "from pynwb.misc import Units        \n",
    "from pynwb.ecephys import SpikeEventSeries\n",
    "import shutil\n",
    "import logging\n",
    "import h5py\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "# os.environ['HDF5_USE_FILE_LOCKING'] = 'TRUE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():   # Browse through ALL objects\n",
    "    if isinstance(obj, h5py.File):   # Just HDF5 files\n",
    "        try:\n",
    "            obj.close()\n",
    "        except: print('hi')\n",
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def read_names(filename):\n",
    "    assignment  = filename.split('.')[0].split('-')[1]\n",
    "    number      = filename.split('.')[0].split('-')[2]\n",
    "    return np.asarray([assignment, number])\n",
    "\n",
    "def create_nwb(config, path):\n",
    "\n",
    "    SessionDate = path.split('/')[-1].split('.')[-2].split('_')[0]\n",
    "    SessionTime = path.split('/')[-1].split('.')[-2].split('_')[1]\n",
    "    SubjectName = path.split('/')[-1].split('.')[1].split('_')[1]\n",
    "    date_format = \"%Y%m%d %H%M%S\"\n",
    "\n",
    "    if config['subject']['subject_id'].lower() != SubjectName.lower():\n",
    "        raise ValueError(\"Subject Name incorrect.\")\n",
    "        \n",
    "    session_start_time_ = datetime.strptime(SessionDate+' '+SessionTime, date_format)\n",
    "    # Define the timezone you want to use (e.g., 'US/Eastern' for Boston)\n",
    "    desired_timezone = pytz.timezone('US/Eastern')\n",
    "    session_start_time = desired_timezone.localize(session_start_time_)\n",
    "\n",
    "    ################ CREATE NWB FILE WITH METADATA ################################\n",
    "    ###############################################################################\n",
    "    nwbfile = NWBFile(\n",
    "        session_description     = config['session_info']['session_description'],\n",
    "        identifier              = config['metadata']['identifier'],\n",
    "        session_start_time      = session_start_time,\n",
    "        file_create_date        = config['metadata']['file_create_date'],\n",
    "        experimenter            = config['general']['lab_info']['experimenter'],\n",
    "        experiment_description  = config['general']['experiment_info']['experiment_description'],\n",
    "        session_id              = config['session_info']['session_id'],\n",
    "        lab                     = config['general']['lab_info']['lab'],                     \n",
    "        institution             = config['general']['lab_info']['institution'],                                    \n",
    "        keywords                = config['general']['experiment_info']['keywords'],\n",
    "        protocol                = config['general']['experiment_info']['protocol'],\n",
    "        related_publications    = config['general']['experiment_info']['related_publications'],\n",
    "        surgery                 = config['general']['experiment_info']['surgery']\n",
    "    )\n",
    "\n",
    "    ################ CREATE SUBJECT ################################################\n",
    "    ################################################################################\n",
    "    nwbfile.subject = Subject(\n",
    "        subject_id  = config['subject']['subject_id'],\n",
    "        date_of_birth= config['subject']['date_of_birth'],\n",
    "        species     = config['subject']['species'],\n",
    "        sex         = config['subject']['sex'],\n",
    "    )\n",
    "\n",
    "    ################ CREATE HARDWARE LINKS #########################################\n",
    "    ################################################################################\n",
    "    nwbfile.create_device(\n",
    "        name        = config['hardware']['system_name'], \n",
    "        description = config['hardware']['system_description'], \n",
    "        manufacturer= config['hardware']['system_manuf']\n",
    "    )\n",
    "\n",
    "    nwbfile.create_device(\n",
    "        name        = config['hardware']['adapter_manuf'], \n",
    "        description = config['hardware']['adapter_description'], \n",
    "        manufacturer= config['hardware']['adapter_manuf']\n",
    "    )\n",
    "\n",
    "    nwbfile.create_device(\n",
    "        name        = config['hardware']['monitor_name'], \n",
    "        description = config['hardware']['monitor_description'], \n",
    "        manufacturer= config['hardware']['monitor_manuf']\n",
    "    )\n",
    "\n",
    "    nwbfile.create_device(\n",
    "        name        = config['hardware']['photodiode_name'], \n",
    "        description = config['hardware']['photodiode_description'], \n",
    "        manufacturer= config['hardware']['photodiode_manuf']\n",
    "    )\n",
    "    \n",
    "    nwbfile.create_device(\n",
    "        name        = 'Software Used', \n",
    "        description = str(['Mworks Client: '+config['software']['mwclient_version'],\\\n",
    "                        'Mworks Server: '+config['software']['mwserver_version'],\\\n",
    "                        'OS: '+config['software']['OS'],\\\n",
    "                        'Intan :'+config['software']['intan_version']])\n",
    "    )\n",
    "\n",
    "    ################ CREATE ELECTRODE LINKS ########################################\n",
    "    ################################################################################\n",
    "    electrodes = nwbfile.create_device(\n",
    "        name        = config['hardware']['electrode_name'], \n",
    "        description = config['hardware']['electrode_description'], \n",
    "        manufacturer= config['hardware']['electrode_manuf']\n",
    "    )\n",
    "\n",
    "    all_files = sorted(os.listdir(os.path.join(path, 'SpikeTimes')))\n",
    "    \n",
    "    name_accumulator = []\n",
    "    for file in all_files:\n",
    "        name_accumulator.append(read_names(file))\n",
    "    names = np.vstack(name_accumulator)\n",
    "\n",
    "    nwbfile.add_electrode_column(name=\"label\", description=\"label of electrode\")\n",
    "    groups, count_groups = np.unique(names[:,0], return_counts =True)\n",
    "    ids                  = names[:,1]\n",
    "    counter              = 0\n",
    "    # create ElectrodeGroups A, B, C, ..\n",
    "    for group, count_group in zip(groups, count_groups):\n",
    "        electrode_group = nwbfile.create_electrode_group(\n",
    "            name        = \"group_{}\".format(group),\n",
    "            description = \"Serialnumber: {}. Adapter Version: {}\".format(config['array_info']['array_{}'.format(group)]['serialnumber'],\\\n",
    "                            config['array_info']['array_{}'.format(group)]['adapterversion']),\n",
    "            device      = electrodes,\n",
    "            location    = 'hemisphere, region, subregion: '+str([config['array_info']['array_{}'.format(group)]['hemisphere'],\\\n",
    "                                config['array_info']['array_{}'.format(group)]['region'],\n",
    "                                config['array_info']['array_{}'.format(group)]['subregion']]),\n",
    "            position    = config['array_info']['array_{}'.format(group)]['position']\n",
    "        )\n",
    "\n",
    "        # create Electrodes 001, 002, ..., 032 in ElectrodeGroups per channel\n",
    "        for ichannel in range(count_group):\n",
    "            nwbfile.add_electrode(\n",
    "                group       = electrode_group,\n",
    "                label       = ids[counter],\n",
    "                location    = 'row, col, elec'+str(json.loads(config['array_info']['intan_electrode_labeling_[row,col,id]'])[counter])\n",
    "            )\n",
    "            counter += 1     \n",
    "\n",
    "    ################ ADD SPIKE TIMES ###############################################\n",
    "    ################################################################################\n",
    "\n",
    "    nwbfile.add_unit_column(name=\"unit\", description=\"millisecond\") \n",
    "    for filename, i in zip(sorted(os.listdir(os.path.join(path, 'SpikeTimes'))), range(len(os.listdir(os.path.join(path, 'SpikeTimes'))))):\n",
    "        [assignment, number] = read_names(filename)\n",
    "        file_path = os.path.join(path, 'SpikeTimes', filename)\n",
    "        data = scipy.io.loadmat(file_path, squeeze_me=True,\n",
    "                        variable_names='spike_time_ms')['spike_time_ms']\n",
    "        nwbfile.add_unit(\n",
    "            spike_times = data, \n",
    "            electrodes  = [i],\n",
    "            electrode_group = nwbfile.electrode_groups[f'group_{assignment}'], \n",
    "            unit = 'ms'\n",
    "        )\n",
    "\n",
    "    ################ ADD TRIAL TIMES ###############################################\n",
    "    ################################################################################\n",
    "    last_spike = data[-1]\n",
    "    with open(os.path.join(path, 'NWBInfo.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        line1 = lines[0].split(',')[0]\n",
    "        StimOnnOff = [float(line1.split('/')[0]),float(line1.split('/')[1])] \n",
    "\n",
    "    on_start  = 0\n",
    "    on_dur    = StimOnnOff[1]\n",
    "    off_dur   = StimOnnOff[1]\n",
    "\n",
    "    \n",
    "    nwbfile.add_trial_column(name=\"unit\", description=\"millisecond\")\n",
    "    while on_start < last_spike:\n",
    "\n",
    "        nwbfile.add_trial(\n",
    "            start_time= float(on_start),\n",
    "            stop_time = float(on_start+on_dur),\n",
    "            unit = 'ms')\n",
    "    \n",
    "        on_start += on_dur+off_dur\n",
    "\n",
    "    return nwbfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_psth_from_nwb(nwbfile, path, start_time, stop_time, timebin, n_stimuli=None):\n",
    "\n",
    "    # Find the MWORKS File\n",
    "    with open(os.path.join(path, 'NWBInfo.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        line2 = lines[0].split(',')[1]\n",
    "        ind = line2.split('/').index('intanproc')\n",
    "        mwk_file = glob.glob(os.path.join('/', *line2.split('/')[0:ind], 'mworksproc', \\\n",
    "                '_'.join(map(str, line2.split('/')[ind+1].split('_')[0:3]))+'*_mwk.csv'))   \n",
    "        \n",
    "    assert len(mwk_file) == 1\n",
    "    mwk_file = mwk_file[0]\n",
    "    assert os.path.isfile(mwk_file)==True\n",
    "\n",
    "    ################ MODIFIED FROM THE SPIKE-TOOLS-CHONG CODE ######################\n",
    "    ################################################################################\n",
    "    \n",
    "    mwk_data = pd.read_csv(mwk_file)\n",
    "    mwk_data = mwk_data[mwk_data.fixation_correct == 1]\n",
    "    if 'photodiode_on_us' in mwk_data.keys():\n",
    "        samp_on_ms = np.asarray(mwk_data['photodiode_on_us']) / 1000.\n",
    "        logging.info('Using photodiode signal for sample on time')\n",
    "    else:\n",
    "        samp_on_ms = np.asarray(mwk_data['samp_on_us']) / 1000.\n",
    "        logging.info('Using MWorks digital signal for sample on time')\n",
    "    \n",
    "    # Load spikeTime file for current channel\n",
    "    spikeTimes = nwbfile.units[:].spike_times\n",
    "    # Re-order the psth to image x reps\n",
    "    max_number_of_reps = max(np.bincount(mwk_data['stimulus_presented']))  # Max reps obtained for any image\n",
    "    if max_number_of_reps == 0:\n",
    "        exit()\n",
    "    mwk_data['stimulus_presented'] = mwk_data['stimulus_presented'].astype(int)  # To avoid indexing errors\n",
    "    \n",
    "    if n_stimuli is None:\n",
    "            image_numbers = np.unique(mwk_data['stimulus_presented'])  # TODO: if not all images are shown (for eg, exp cut short), you'll have to manually type in total # images\n",
    "    else:\n",
    "        image_numbers = np.arange(1,n_stimuli+1) # all of my image starts with #1\n",
    "\n",
    "    timebase = np.arange(start_time, stop_time, timebin)\n",
    "    PSTH = np.full((len(image_numbers), max_number_of_reps, len(timebase),spikeTimes.shape[0]), np.nan)\n",
    "\n",
    "    for num in range(spikeTimes.shape[0]):\n",
    "        spikeTime = np.asanyarray(spikeTimes[num])\n",
    "        osamp = 10\n",
    "        psth_bin = np.zeros((len(samp_on_ms), osamp*(stop_time-start_time)))\n",
    "        psth_matrix = np.full((len(samp_on_ms), len(timebase)), np.nan)\n",
    "\n",
    "        for i in range(len(samp_on_ms)):\n",
    "\n",
    "            sidx = np.floor(osamp*(spikeTime[(spikeTime>=(samp_on_ms[i]+start_time))*(spikeTime<(samp_on_ms[i]+stop_time))]-(samp_on_ms[i]+start_time))).astype(int)\n",
    "            psth_bin[i, sidx] = 1\n",
    "            psth_matrix[i] = np.sum(np.reshape(psth_bin[i], [len(timebase), osamp*timebin]), axis=1)\n",
    "        \n",
    "        \n",
    "        psth = np.full((len(image_numbers), max_number_of_reps, len(timebase)), np.nan)  # Re-ordered PSTH\n",
    "\n",
    "        for i, image_num in enumerate(image_numbers):\n",
    "            index_in_table = np.where(mwk_data.stimulus_presented == image_num)[0]\n",
    "            selected_cells = psth_matrix[index_in_table, :]\n",
    "            psth[i, :selected_cells.shape[0], :] = selected_cells\n",
    "\n",
    "        logging.info(psth.shape)\n",
    "        # Save psth data\n",
    "        PSTH[:,:,:,num] = psth\n",
    "        \n",
    "    meta = {'start_time_ms': start_time, 'stop_time_ms': stop_time, 'tb_ms': timebin}\n",
    "    cmbined_psth = {'psth': PSTH, 'meta': meta}\n",
    "\n",
    "    return cmbined_psth\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ...:   0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file created.\n",
      "PSTH added.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ...:   0%|          | 1/201 [01:00<3:22:36, 60.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ...:   0%|          | 1/201 [01:11<3:57:28, 71.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(config_path,\u001b[39m\"\u001b[39m\u001b[39mconfig_nwb.yaml\u001b[39m\u001b[39m\"\u001b[39m) , \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         config \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39mload(f, Loader \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39mFullLoader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m nwbfile \u001b[39m=\u001b[39m create_nwb(config,path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNWB file created.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mh5Files\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(path):\n",
      "\u001b[1;32m/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mSpikeTimes\u001b[39m\u001b[39m'\u001b[39m, filename)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m     data \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(file_path, squeeze_me\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m                     variable_names\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspike_time_ms\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mspike_time_ms\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m     nwbfile\u001b[39m.\u001b[39;49madd_unit(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m         spike_times \u001b[39m=\u001b[39;49m data, \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m         electrodes  \u001b[39m=\u001b[39;49m [i],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m         electrode_group \u001b[39m=\u001b[39;49m nwbfile\u001b[39m.\u001b[39;49melectrode_groups[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgroup_\u001b[39;49m\u001b[39m{\u001b[39;49;00massignment\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m         unit \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mms\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m################ ADD TRIAL TIMES ###############################################\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m################################################################################\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m last_spike \u001b[39m=\u001b[39m data[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/utils.py:644\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    643\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/pynwb/file.py:767\u001b[0m, in \u001b[0;36mNWBFile.add_unit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[39mAdd a unit to the unit table.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mSee :py:meth:`~hdmf.common.table.DynamicTable.add_row` for more details.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \n\u001b[1;32m    765\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__check_units()\n\u001b[0;32m--> 767\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munits\u001b[39m.\u001b[39;49madd_unit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/utils.py:644\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    643\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/pynwb/misc.py:206\u001b[0m, in \u001b[0;36mUnits.add_unit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m@docval\u001b[39m({\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mspike_times\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39marray_data\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdoc\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mthe spike times for each unit\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    184\u001b[0m          \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39mNone\u001b[39;00m,)},\n\u001b[1;32m    185\u001b[0m         {\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mobs_intervals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39marray_data\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m         allow_extra\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_unit\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    203\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m    Add a unit to this table\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49madd_row(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39melectrodes\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m    208\u001b[0m         elec_col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m'\u001b[39m\u001b[39melectrodes\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtarget\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/utils.py:644\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    643\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/common/table.py:645\u001b[0m, in \u001b[0;36mDynamicTable.add_row\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__df_cols[colnum]\n\u001b[1;32m    644\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, VectorIndex):\n\u001b[0;32m--> 645\u001b[0m     c\u001b[39m.\u001b[39;49madd_vector(data[colname])\n\u001b[1;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m     c\u001b[39m.\u001b[39madd_row(data[colname])\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/common/table.py:132\u001b[0m, in \u001b[0;36mVectorIndex.add_vector\u001b[0;34m(self, arg, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39madd_vector(a)\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget\u001b[39m.\u001b[39;49mextend(arg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__check_precision(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget)))\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/common/table.py:87\u001b[0m, in \u001b[0;36mVectorData.extend\u001b[0;34m(self, ar, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m#################################################################################\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m# Each subclass of VectorData should have its own extend method to ensure\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m# functionality AND efficiency of the extend operation. However, because currently\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# they do not all have one of these methods, the only way to ensure functionality\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m# is with calls to add_row. Because that is inefficient for basic VectorData,\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m# this check is added to ensure we always call extend on a basic VectorData.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__mro__\u001b[39m[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m VectorData:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mextend(ar)\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ar:\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/container.py:851\u001b[0m, in \u001b[0;36mData.extend\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[39mThe extend_data method adds all the elements of the iterable arg to the\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[39mend of the data of this Data container.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \n\u001b[1;32m    848\u001b[0m \u001b[39m:param arg: The iterable to add to the end of this VectorData\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterm_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__data \u001b[39m=\u001b[39m extend_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__data, arg)\n\u001b[1;32m    852\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    853\u001b[0m     bad_data \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/data_utils.py:39\u001b[0m, in \u001b[0;36mextend_data\u001b[0;34m(data, arg)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Add all the elements of the iterable arg to the end of data.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39m:param data: The array to extend\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m:type data: list, DataIO, np.ndarray, h5py.Dataset\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m, DataIO)):\n\u001b[0;32m---> 39\u001b[0m     data\u001b[39m.\u001b[39;49mextend(arg)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     41\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inventory   = '/braintree/home/aliya277/dandi_brainscore/inventory'\n",
    "start_time  = 0\n",
    "stop_time   = 300\n",
    "timebin     = 10\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for folder, num_file in tqdm(zip(os.listdir(inventory), range(len(os.listdir(inventory)))), \\\n",
    "    total = len(os.listdir(inventory)), desc='Processing ...'):\n",
    "\n",
    "\n",
    "    path = os.path.join(inventory, folder)\n",
    "    SessionName = folder\n",
    "    config_path = '/om/user/aliya277/dandi_brainscore'\n",
    "    with open(os.path.join(config_path,\"config_nwb.yaml\") , \"r\") as f:\n",
    "            config = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "    nwbfile = create_nwb(config,path)\n",
    "    print('NWB file created.')\n",
    "\n",
    "    if 'h5Files' in os.listdir(path):\n",
    "        filename = os.listdir(os.path.join(path, 'h5Files'))[0]\n",
    "        file = h5py.File(os.path.join(path, 'h5Files', filename),'r+') \n",
    "        data = file['psth'][:]\n",
    "        file.close()\n",
    "\n",
    "\n",
    "        nwbfile.add_scratch(\n",
    "            data,\n",
    "            name=\"psth\",\n",
    "            description=\"psth, uncorrected [channels x stimuli x reps x timebins]\",\n",
    "            )\n",
    "        print('PSTH added.')\n",
    "        \n",
    "    try: io.close()\n",
    "    except:pass\n",
    "    \n",
    "    io = NWBHDF5IO(os.path.join(path, f\"{SessionName}.nwb\"), \"w\") \n",
    "    io.write(nwbfile)\n",
    "    io.close()\n",
    "    print(\"File saved.\")\n",
    "\n",
    "    else: counter +=1\n",
    "        # psth    = get_psth_from_nwb(nwbfile, path, start_time, stop_time, timebin)\n",
    "        # data    = psth['psth']\n",
    "\n",
    "print(f'{counter} SpikeTimes do not have an h5 file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pico_normalizers_230823\n",
      "['/braintree/data2/active/users/sgouldin/projects/normalizers/monkeys/pico/mworksproc/pico_normalizers_230823_124104_mwk.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path      = '/om/user/aliya277/inventory/norm_FOSS.sub_pico.20230823_124104.proc'\n",
    "\n",
    "with open(os.path.join(path, 'NWBInfo.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        line2 = lines[0].split(',')[1]\n",
    "        ind = line2.split('/').index('intanproc')\n",
    "        mwk_file = glob.glob(os.path.join('/', *line2.split('/')[0:ind], 'mworksproc', \\\n",
    "                '_'.join(map(str, line2.split('/')[ind+1].split('_')[0:3]))+'*_mwk.csv'))\n",
    "                \n",
    "print(mwk_file)\n",
    "\n",
    "# temp_path = '/braintree/home/aliya277/dandi_brainscore/norm_FOSS.sub_pico.20230823_124104.proc'\n",
    "# try: os.mkdir(temp_path)\n",
    "# except: pass\n",
    "\n",
    "# SessionName = path.split('/')[-1]\n",
    "# config_path = '/om/user/aliya277/dandi_brainscore'\n",
    "# with open(os.path.join(config_path,\"config_nwb.yaml\") , \"r\") as f:\n",
    "#         config = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "# nwbfile = create_nwb(config,path)\n",
    "# nwbfile = save_nwb(nwbfile, path)\n",
    "\n",
    "# nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "stop_time = 300\n",
    "timebin = 10\n",
    "\n",
    "\n",
    "def get_psth_from_nwb(nwbfile, path, start_time, stop_time, timebin, n_stimuli=None):\n",
    "\n",
    "    # Find the MWORKS File\n",
    "    with open(os.path.join(path, 'NWBInfo.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        line2 = lines[0].split(',')[1]\n",
    "        ind = line2.split('/').index('intanproc')\n",
    "        mwk_file = os.path.join('/', *line2.split('/')[0:ind], 'mworksproc', line2.split('/')[ind+1]+'_mwk.csv')\n",
    "    assert os.path.isfile(mwk_file)==True\n",
    "\n",
    "    ################ MODIFIED FROM THE SPIKE-TOOLS-CHONG CODE ######################\n",
    "    ################################################################################\n",
    "    \n",
    "    mwk_data = pd.read_csv(mwk_file)\n",
    "    mwk_data = mwk_data[mwk_data.fixation_correct == 1]\n",
    "    if 'photodiode_on_us' in mwk_data.keys():\n",
    "        samp_on_ms = np.asarray(mwk_data['photodiode_on_us']) / 1000.\n",
    "        logging.info('Using photodiode signal for sample on time')\n",
    "    else:\n",
    "        samp_on_ms = np.asarray(mwk_data['samp_on_us']) / 1000.\n",
    "        logging.info('Using MWorks digital signal for sample on time')\n",
    "    \n",
    "    # Load spikeTime file for current channel\n",
    "    spikeTimes = nwbfile.units[:].spike_times\n",
    "    # Re-order the psth to image x reps\n",
    "    max_number_of_reps = max(np.bincount(mwk_data['stimulus_presented']))  # Max reps obtained for any image\n",
    "    if max_number_of_reps == 0:\n",
    "        exit()\n",
    "    mwk_data['stimulus_presented'] = mwk_data['stimulus_presented'].astype(int)  # To avoid indexing errors\n",
    "    \n",
    "    if n_stimuli is None:\n",
    "            image_numbers = np.unique(mwk_data['stimulus_presented'])  # TODO: if not all images are shown (for eg, exp cut short), you'll have to manually type in total # images\n",
    "    else:\n",
    "        image_numbers = np.arange(1,n_stimuli+1) # all of my image starts with #1\n",
    "\n",
    "    timebase = np.arange(start_time, stop_time, timebin)\n",
    "    PSTH = np.full((len(image_numbers), max_number_of_reps, len(timebase),spikeTimes.shape[0]), np.nan)\n",
    "\n",
    "    for num in range(spikeTimes.shape[0]):\n",
    "        spikeTime = np.asanyarray(spikeTimes[num])\n",
    "        osamp = 10\n",
    "        psth_bin = np.zeros((len(samp_on_ms), osamp*(stop_time-start_time)))\n",
    "        psth_matrix = np.full((len(samp_on_ms), len(timebase)), np.nan)\n",
    "\n",
    "        for i in range(len(samp_on_ms)):\n",
    "\n",
    "            sidx = np.floor(osamp*(spikeTime[(spikeTime>=(samp_on_ms[i]+start_time))*(spikeTime<(samp_on_ms[i]+stop_time))]-(samp_on_ms[i]+start_time))).astype(int)\n",
    "            psth_bin[i, sidx] = 1\n",
    "            psth_matrix[i] = np.sum(np.reshape(psth_bin[i], [len(timebase), osamp*timebin]), axis=1)\n",
    "        \n",
    "        \n",
    "        psth = np.full((len(image_numbers), max_number_of_reps, len(timebase)), np.nan)  # Re-ordered PSTH\n",
    "\n",
    "        for i, image_num in enumerate(image_numbers):\n",
    "            index_in_table = np.where(mwk_data.stimulus_presented == image_num)[0]\n",
    "            selected_cells = psth_matrix[index_in_table, :]\n",
    "            psth[i, :selected_cells.shape[0], :] = selected_cells\n",
    "\n",
    "        logging.info(psth.shape)\n",
    "        # Save psth data\n",
    "        PSTH[:,:,:,num] = psth\n",
    "        \n",
    "    meta = {'start_time_ms': start_time, 'stop_time_ms': stop_time, 'tb_ms': timebin}\n",
    "    cmbined_psth = {'psth': PSTH, 'meta': meta}\n",
    "\n",
    "    return cmbined_psth\n",
    "    \n",
    "# psth = get_psth_from_nwb(nwbfile, path, start_time, stop_time, timebin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nwb(nwbfile, path):\n",
    "    \n",
    "    SessionName = path.split('/')[-1]\n",
    "\n",
    "    # Crete Temporary path on BrainTree (Openmind Did not Allow Saving of H5 Files.)\n",
    "    temp_path = '/braintree/home/aliya277/dandi_brainscore/inventory'\n",
    "    try: os.mkdir(temp_path)\n",
    "    except: pass\n",
    "\n",
    "    # Save NWB File on Braintree\n",
    "    io = NWBHDF5IO(os.path.join(temp_path, f\"{SessionName}.nwb\"), \"w\") \n",
    "    io.write(nwbfile)\n",
    "    io.close()\n",
    "\n",
    "    # Copy NWB to Inventory Directory on Openmind\n",
    "    shutil.copy2(os.path.join(temp_path, f\"{SessionName}.nwb\"), os.path.join(path, f\"{SessionName}.nwb\"))   \n",
    "    \n",
    "    # Remove Temporary File and Folder on Braintree\n",
    "    os.remove(os.path.join(temp_path, f\"{SessionName}.nwb\"))\n",
    "    os.rmdir(os.path.join(temp_path))\n",
    "\n",
    "    return nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'psth' already exists in NWBFile 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m psth[\u001b[39m'\u001b[39m\u001b[39mpsth\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m nwbfile\u001b[39m.\u001b[39;49madd_scratch(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     data,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpsth\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpsth, uncorrected [channels x stimuli x reps x timebins]\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bopenmind.mit.edu/om/user/aliya277/dandi_brainscore/create_proc_nwb.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/utils.py:644\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    643\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/pynwb/file.py:1097\u001b[0m, in \u001b[0;36mNWBFile.add_scratch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[39mif\u001b[39;00m description \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1095\u001b[0m         warn(\u001b[39m'\u001b[39m\u001b[39mThe description argument is ignored when adding an NWBContainer, ScratchData, or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mDynamicTable to scratch.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_scratch(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/utils.py:644\u001b[0m, in \u001b[0;36mdocval.<locals>.dec.<locals>.func_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    643\u001b[0m     pargs \u001b[39m=\u001b[39m _check_args(args, kwargs)\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m func(args[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dandibs/lib/python3.10/site-packages/hdmf/container.py:1031\u001b[0m, in \u001b[0;36mMultiContainerInterface.__make_add.<locals>._func\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mif\u001b[39;00m tmp\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m d:\n\u001b[1;32m   1030\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (tmp\u001b[39m.\u001b[39mname, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> 1031\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1032\u001b[0m     d[tmp\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m tmp\n\u001b[1;32m   1033\u001b[0m \u001b[39mreturn\u001b[39;00m container\n",
      "\u001b[0;31mValueError\u001b[0m: 'psth' already exists in NWBFile 'root'"
     ]
    }
   ],
   "source": [
    "data = psth['psth']\n",
    "\n",
    "nwbfile.add_scratch(\n",
    "    data,\n",
    "    name=\"psth\",\n",
    "    description=\"psth, uncorrected [channels x stimuli x reps x timebins]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 86, 21, 30)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwbfile.scratch['psth'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5path = '/om/user/aliya277/inventory/norm_FOSS.sub_pico.20230823_124104.proc/h5Files/230823.pico.rsvp.normalizers.experiment_psth_raw.h5'\n",
    "\n",
    "def open_h5(path):\n",
    "    \n",
    "    filename = path.split('/')[-1]\n",
    "    # Crete Temporary path on BrainTree (Openmind Did not Allow Saving of H5 Files.)\n",
    "    temp_path = '/braintree/home/aliya277/dandi_brainscore/inventory'\n",
    "    try: os.mkdir(temp_path)\n",
    "    except: pass\n",
    "\n",
    "\n",
    "    # Copy File to Temporary Path\n",
    "    shutil.copy2(os.path.join(path), os.path.join(temp_path, filename))   \n",
    "\n",
    "    file = h5py.File(os.path.join(temp_path, filename),'r+')    \n",
    "\n",
    "    return file\n",
    "\n",
    "def close_h5(path):\n",
    "\n",
    "    filename = path.split('/')[-1]\n",
    "    temp_path = '/braintree/home/aliya277/dandi_brainscore/inventory'\n",
    "    os.remove(os.path.join(temp_path, filename))\n",
    "    os.rmdir(temp_path)\n",
    "\n",
    "file = open_h5(h5path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(psth['psth'], file['psth'][:], equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0      [69.2, 135.55, 207.55, 242.9, 281.95, 331.5, 3...\n",
       "1      [22.1, 57.3, 63.9, 135.35, 167.1, 175.6, 225.8...\n",
       "2      [58.1, 69.15, 167.7, 171.1, 171.3, 286.9, 362....\n",
       "3      [16.9, 158.04999999999998, 237.9, 304.09999999...\n",
       "4      [49.75, 68.9, 87.65, 115.1, 342.95, 412.650000...\n",
       "                             ...                        \n",
       "187    [2.6, 5.3, 81.3, 155.35, 185.35, 251.649999999...\n",
       "188    [35.2, 164.14999999999998, 164.70000000000002,...\n",
       "189    [35.2, 155.35, 251.8, 286.95, 287.1, 287.4, 29...\n",
       "190    [2.6, 162.35, 198.8, 251.5, 251.7, 287.2, 294....\n",
       "191    [46.449999999999996, 73.85, 81.44999999999999,...\n",
       "Name: spike_times, Length: 192, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwbfile.units[:].spike_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a794e277a4c49fa8734cde16f0468e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='…"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb2widget(nwbfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
