{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook was used to create a standartized inventory for pico, including the spiketimes and psth h5 files. additionally, the information at hand was extracted from the excel file and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "import shutil\n",
    "import re\n",
    "from ruamel.yaml import YAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_directories_with_name(root_dir, directory_name):\n",
    "    directory_paths = []\n",
    "    for foldername, subfolders, _ in os.walk(root_dir):\n",
    "        if directory_name in subfolders:\n",
    "            directory_paths.append(os.path.join(foldername, directory_name))\n",
    "    return directory_paths\n",
    "\n",
    "############### Find Directories of SpikeTimes ################################\n",
    "###############################################################################\n",
    "\n",
    "parent_directory = '/braintree/data2/active/users/sgouldin/projects'\n",
    "target_directory_name = 'spikeTime'\n",
    "spikeTime_directories = find_directories_with_name(parent_directory, target_directory_name)\n",
    "\n",
    "spike_parent = []\n",
    "for path in spikeTime_directories:\n",
    "    spike_parent.append(os.path.join(*path.split('/')[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    \"\"\"\n",
    "    Get the Dates from the Excel file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        dates = date.split('/')\n",
    "        if len(dates[-1])>2:year = dates[-1]\n",
    "        else: year=f'20{dates[-1]}'\n",
    "        if len(dates[0])>1: month = dates[0]\n",
    "        else: month = f'0{dates[0]}'\n",
    "        if len(dates[1])>1:day=dates[1]\n",
    "        else:day=f'0{dates[1]}'\n",
    "        \n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            dates = str(date).split()[0].split('-')\n",
    "            if len(dates)==3:\n",
    "                year=dates[0]\n",
    "                month=dates[1]\n",
    "                if len(dates[2])>1:day=dates[2]\n",
    "                else:day=f'0{dates[2]}'\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try: return day, month, year\n",
    "    except: return 0,0,0\n",
    "    \n",
    "\n",
    "def find_files_with_pattern(root_dir, pattern):\n",
    "    \"\"\"\n",
    "    Find Associated .h5 File for each SpikeTime Folder.\n",
    "    \"\"\"\n",
    "    return [os.path.join(foldername, filename) for foldername, subfolders, filenames in os.walk(root_dir) for filename in filenames if filename.startswith(pattern) and filename.endswith('.h5')]\n",
    "\n",
    "\n",
    "############### Create Storage Dir and Load Excel File ########################\n",
    "###############################################################################\n",
    "   \n",
    "storage_dir = '/braintree/home/aliya277/inventory'\n",
    "try: os.mkdir(storage_dir)\n",
    "except: pass\n",
    "os.chdir('/braintree/home/aliya277')\n",
    "path = 'dandi_brainscore/Pipeline Monkey Schedule New.xlsx'\n",
    "data = pd.read_excel(path, sheet_name='pico')\n",
    "new_header = data.iloc[0]  \n",
    "data = data[1:]       \n",
    "data.columns = new_header  \n",
    "data = data.fillna('empty')  \n",
    "\n",
    "\n",
    "for spike in (spikeTime_directories):\n",
    "\n",
    "    ############### Get Recording Info from FileName ##############################\n",
    "    ###############################################################################\n",
    "    ind = spike.split('/').index('intanproc')\n",
    "    SubjectName     = spike.split('/')[ind-1]\n",
    "    ImageSetName_v1 = spike.split('/')[ind-3]\n",
    "    Date            = re.findall('..',spike.split('/')[ind+1].split('_')[-2])\n",
    "    year            = f'20{Date[0]}'\n",
    "    month           = Date[1]\n",
    "    day             = Date[2]\n",
    "    SessionTime     = spike.split('/')[ind+1].split('_')[-1]\n",
    "\n",
    "    \n",
    "    if SubjectName == 'pico':\n",
    "\n",
    "\n",
    "        ############### Filter by Date in FileName and ExcelDate ##########################\n",
    "        ###############################################################################\n",
    "        for date,index in zip(data['Date'], range(1,len(data))):\n",
    "            exl_day, exl_month, exl_year = get_date(date)\n",
    "\n",
    "            if exl_day+exl_month+exl_year == day+month+year:\n",
    "\n",
    "\n",
    "                ############### Filter by FileName and ExcelStimulus ##########################\n",
    "                ###############################################################################\n",
    "                list = [data['Stimuli'][index]]\n",
    "                for i in range(1,10):\n",
    "                    try:\n",
    "                        if data['Date'][index+i] == 'empty':\n",
    "                            list.append(data['Stimuli'][index+i])\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            break\n",
    "                    except:break\n",
    "                found_item = False\n",
    "\n",
    "                for item, i in zip(list, range(len(list))): \n",
    "                    if item.lower() in ImageSetName_v1:\n",
    "                        ImageSetName = data['Stimuli'][index+i]\n",
    "                        # StimOnnOff   = data['ON/OFF (ms)'][index+i]\n",
    "                        RecInfo      = data.iloc[[index+i-1]].to_dict('records')[0]\n",
    "                        found_item = True\n",
    "\n",
    "                if found_item == False:\n",
    "                    for item, i in zip(list, range(len(list))):\n",
    "                        spike_new = ImageSetName_v1.lower().replace('-', '_').split('_')\n",
    "                        item_new = item.lower().replace('-', '_').split('_') \n",
    "\n",
    "                        if set(item_new).intersection(set(spike_new)) == set(item_new) or set(spike_new).intersection(set(item_new)) == set(spike_new):\n",
    "                            ImageSetName = data['Stimuli'][index+i]\n",
    "                            # StimOnnOff   = data['ON/OFF (ms)'][index+i]\n",
    "                            RecInfo      = data.iloc[[index+i-1]].to_dict('records')[0]\n",
    "                            found_item = True\n",
    "                \n",
    "                ############### Create Standartized Directory Name ############################\n",
    "                ###############################################################################\n",
    "                if found_item == True:\n",
    "                    SessionDate = f'{year}{month}{day}'\n",
    "                    if ImageSetName == 'Normalizers':\n",
    "                        directory = f'norm_FOSS.sub_{SubjectName}.{SessionDate}_{SessionTime}.proc'\n",
    "                    elif ImageSetName == 'Normalizers-HVM':\n",
    "                        directory = f'norm_HVM.sub_{SubjectName}.{SessionDate}_{SessionTime}.proc'\n",
    "                    else: \n",
    "                        directory = f'exp_{ImageSetName}.sub_{SubjectName}.{SessionDate}_{SessionTime}.proc'\n",
    "\n",
    "                    try: os.mkdir(os.path.join(storage_dir, directory))\n",
    "                    except: pass\n",
    "\n",
    "\n",
    "                    ############### Copy Files in Respective Inventory Directory ##################\n",
    "                    ###############################################################################\n",
    "                    matching_h5files = find_files_with_pattern(os.path.join('/', *spike.split('/')[0:10]), f'{Date[0]}{Date[1]}{Date[2]}')\n",
    "                    \n",
    "                    # shutil.copytree(spike, os.path.join(storage_dir, directory, 'SpikeTimes'))\n",
    "                    # if matching_h5files:\n",
    "                    #     for files in matching_h5files:\n",
    "                    #         try: os.mkdir(os.path.join(storage_dir, directory, 'h5Files'))\n",
    "                    #         except: pass\n",
    "                    #         shutil.copy2(files, os.path.join(storage_dir, directory, 'h5Files', files.split('/')[-1]))\n",
    "\n",
    "                    ############### Create .txt File with Relevant Info for NWB ###################\n",
    "                    ###############################################################################\n",
    "                    \n",
    "                    RecInfo['intanproc'] = spike\n",
    "                    RecInfo['SessionDate'] = SessionDate\n",
    "                    RecInfo['SessionTime'] = SessionTime\n",
    "                    yaml = YAML()\n",
    "                    with open(os.path.join(storage_dir, directory,\"RecInfo.yaml\"), 'w') as yamlfile:\n",
    "                        yaml.dump((RecInfo), yamlfile)\n",
    "\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    print('Wrong Names: ', month, day, year, list, '\\t', spike.split('/')[ind-3], index)\n",
    "                    pass\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_with_extension(root_dir, extension):\n",
    "    file_paths = []\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in fnmatch.filter(filenames, f'*.{extension}'):\n",
    "            file_paths.append(os.path.join(foldername, filename))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "############### Find Directories for PSTH h5 Files ############################\n",
    "###############################################################################\n",
    "parent_directory = '/braintree/data2/active/users/sgouldin/projects'\n",
    "extension = 'h5'\n",
    "h5_files = find_files_with_extension(parent_directory, extension)\n",
    "\n",
    "h5_parent = []\n",
    "for path in h5_files:\n",
    "    h5_parent.append(os.path.join(*path.split('/')[0:10]))\n",
    "\n",
    "############### Compare SpikeTimes Directoriy and h5 Directory ################\n",
    "###############################################################################\n",
    "spikeTime_set = set(spike_parent)\n",
    "h5_set = set(h5_parent)\n",
    "\n",
    "# Find the directories that are unique to each set\n",
    "unique_to_spikeTime = spikeTime_set - h5_set\n",
    "unique_to_h5 = h5_set - spikeTime_set\n",
    "\n",
    "# Check if the sets are different\n",
    "if len(unique_to_spikeTime) > 0 or len(unique_to_h5) > 0:\n",
    "    print(\"The sets are different.\")\n",
    "else:\n",
    "    print(\"The sets are the same.\")\n",
    "\n",
    "# Print the unique directories\n",
    "print(\"Directories unique to 'spikeTime':\")\n",
    "print(unique_to_spikeTime)\n",
    "\n",
    "print(\"Directories unique to 'h5':\")\n",
    "print(unique_to_h5)\n",
    "\n",
    "\n",
    "############### Manually Correct if Needed  ###################################\n",
    "###############################################################################\n",
    "# manually copying one file:\n",
    "# for dir in unique_to_other:\n",
    "#     if dir.split('/')[-1] == 'pico':\n",
    "#         print(dir)\n",
    "#         file = os.listdir(os.path.join('/'+dir, 'h5'))[0]\n",
    "#         shutil.copy2(os.path.join('/'+dir, 'h5', file ), '/braintree/home/aliya277/inventory/exp_robustness_guy_d0_v7_chong_dryrun.sub_pico.20230717_130030.proc/h5Files')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
